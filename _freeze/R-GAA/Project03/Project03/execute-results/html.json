{
  "hash": "36ee2a6bdef3199ef19c1eb96d98909e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Take-home Exercise 3\"\nauthor: \"Ha Duc Tien\"\ndate: \"October 21, 2024\"\ndate-modified: \"last-modified\"\nexecute: \n  eval: true\n  echo: true\n  warning: false\n  freeze: true\n---\n\n\n\n\n# 1. Objectives and Tasks and packages used\n\nIn this take-home exercise, I am required to calibrate a predictive model to predict HDB resale prices between July-September 2024 by using HDB resale transaction records in 2023. For the purpose of this take-home exercise, HDB Resale Flat Prices provided by Data.gov.sg should be used as the core data set. The study should focus on either three-room, four-room or five-room flat.\n\nhttps://isss626-ay2024-25aug.netlify.app/take-home_ex03b \n\nThe below packages are used and loaded in using the `p_load()` function of `pacman` package\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse, sf, httr, jsonlite, tmap, SpatialAcc, \n               spdep, GWmodel, SpatialML, rsample, Metrics, kableExtra,\n               knitr, ggstatsplot, spatstat, see, performance)\n```\n:::\n\n\n\n\n# 2. The data\n\nBelow is a list of predictors and data used in this study\n\nStructural factors all of this are locate within the [Resale flat prices based on registration date from Jan-2017 onwards](https://data.gov.sg/datasets/d_8b84c4ee58e3cfc0ece0d773c8ca6abc/view) under the *resale.csv* file\n-   Area of the unit\n-   Floor level\n-   Remaining lease\n\nLocational factors\n\n-   Proxomity to CBDs based on the [Master Plan 2014 Subzone Boundary (Web)](https://data.gov.sg/datasets/d_d14da225fccf921049ab64238ff473d9/view)\n-   Proximity to eldercares from Eldercare Services (SHP) [data.gov.sg](https://data.gov.sg/datasets/d_3545b068e3f3506c56b2cb6b6117b884/view)\n-   Proximity to market/food centres is based on NEA Market and Food Centre from [data.gov.sg](https://data.gov.sg/datasets/d_a57a245b3cf3ec76ad36d55393a16e97/view)\n-   Proximity to MRTs or MRTs exit points are based on LTA MRT Station Exit (GEOJSON) from [data.gov.sg](https://data.gov.sg/datasets/d_b39d3a0871985372d7e1637193335da5/view)\n-   Proximity to parks based on the Parks from NPARKS (National Parks Board) from [data.gov.sg](https://data.gov.sg/datasets/d_0542d48f0991541706b58059381a6eca/view)\n-   Proximity to shopping malls this is based on a list of shopping malls namaes extracted from [Wikipedia](https://en.wikipedia.org/wiki/List_of_shopping_malls_in_Singapore)\n-   Proximity to supermarkets based on the Supermarkets (KML) from SFA (Singapore Food Agency) from [data.gov.sg](https://data.gov.sg/datasets/d_8a77ee0446716b2ce475a587004afc73/view)\n-   Numbers of kindergartens within 350m from the Kindergartens data from ECDA (Early Childhood Development Agency) from [data.gov.sg](https://data.gov.sg/datasets/d_95aa63998d7de94dd4cb3e8e43a5f6d5/view)\n-   Numbers of childcare centres within 350m probabably based on the Child Care Services from [data.gov.sg](https://data.gov.sg/datasets/d_5d668e3f544335f8028f546827b773b4/view), but the actual data was from [Chapter 4](https://r4gdsa.netlify.app/chap04.html#the-data)\n-   Numbers of bus stops within 350m data is based on the Bus Stops data from LTA [datamall](https://datamall.lta.gov.sg/content/datamall/en/dynamic-data.html)\n-   Numbers of preschools within 350m based on Pre-Schools Location data from ECDA (Early Childhood Development Agency) from [data.gov.sg](https://data.gov.sg/datasets/d_61eefab99958fd70e6aab17320a71f1c/view)\n-   Numbers of CHAS within 1km based on the CHAS Clinics data from MOH (Ministry of Health) from [data.gov.sg](https://data.gov.sg/datasets/d_65d11d02ab0246cec53bfc995c782628/view)\n-   Numbers of primary schools within 1km The data of schools is gotten from the [data.gov.sg](https://data.gov.sg/datasets/d_688b934f82c1059ed0a6993d2a829089/view) website that has a list of all schools and their addresses\n\n\n# 3. Data prepratation and wrangling\n\n## 3.1 First phase of data preparation and wrangling\n\n### Resale data \n\nFirst the resale data will be loaded into data call `resale` using the `read_cvs()`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresale <- read_csv(\"data/non-geo/resale.csv\") %>%\n  filter(month >= \"2023-01\" & month <= \"2024-09\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(resale)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 11\n  month town  flat_type block street_name storey_range floor_area_sqm flat_model\n  <chr> <chr> <chr>     <chr> <chr>       <chr>                 <dbl> <chr>     \n1 2023… ANG … 2 ROOM    406   ANG MO KIO… 01 TO 03                 44 Improved  \n2 2023… ANG … 2 ROOM    323   ANG MO KIO… 04 TO 06                 49 Improved  \n3 2023… ANG … 2 ROOM    314   ANG MO KIO… 04 TO 06                 44 Improved  \n4 2023… ANG … 2 ROOM    314   ANG MO KIO… 07 TO 09                 44 Improved  \n5 2023… ANG … 2 ROOM    170   ANG MO KIO… 01 TO 03                 45 Improved  \n6 2023… ANG … 3 ROOM    225   ANG MO KIO… 04 TO 06                 67 New Gener…\n# ℹ 3 more variables: lease_commence_date <dbl>, remaining_lease <chr>,\n#   resale_price <dbl>\n```\n\n\n:::\n:::\n\n\n\nFirst look at the data we could see that there is a range of story under `storey_range` and `remaining_lease` are actully a string instead of numeric data that need to be convert to a better data for better modelling later. Other data such as `floor_area_sqm` and `resale_price` seems to be in appropriate\n\n\nQuickly checking unique data for `storey_range`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(resale$storey_range)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"01 TO 03\" \"04 TO 06\" \"07 TO 09\" \"25 TO 27\" \"10 TO 12\" \"13 TO 15\"\n [7] \"16 TO 18\" \"22 TO 24\" \"19 TO 21\" \"34 TO 36\" \"28 TO 30\" \"37 TO 39\"\n[13] \"31 TO 33\" \"40 TO 42\" \"43 TO 45\" \"46 TO 48\" \"49 TO 51\"\n```\n\n\n:::\n:::\n\n\n\nThere is 17 unique data which I'll convert to numeric from 1-17 separately..\n\nThe `remaining_lease` would go through being separate into `remaining_lease_yr` column and `remaining_lease_mth` separated then recalculate under `remaining_lease_time` with function `remaining_lease_yr`*12 + `remaining_lease_mth`.\n\nAll of the above steps would be done with the code below creating `resale_tidy` data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_tidy <- resale %>%\n  mutate(address = paste(block,street_name)) %>%\n  mutate(remaining_lease_yr = as.integer(\n    str_sub(remaining_lease, 0, 2)))%>%\n  mutate(remaining_lease_mth = as.integer(\n    str_sub(remaining_lease, 9, 11))) %>%\n  mutate_if(is.numeric , replace_na, replace = 0) %>%\n  mutate(remaining_lease_time = remaining_lease_yr*12 + remaining_lease_mth) %>%\n  mutate(storey_level =  case_when(\n    storey_range == \"01 TO 03\" ~ as.integer(1),\n    storey_range == \"04 TO 06\" ~ as.integer(2),\n    storey_range == \"07 TO 09\" ~ as.integer(3),\n    storey_range == \"10 TO 12\" ~ as.integer(4),\n    storey_range == \"13 TO 15\" ~ as.integer(5),\n    storey_range == \"16 TO 18\" ~ as.integer(6),\n    storey_range == \"19 TO 21\" ~ as.integer(7),\n    storey_range == \"22 TO 24\" ~ as.integer(8),\n    storey_range == \"25 TO 27\" ~ as.integer(9),\n    storey_range == \"28 TO 30\" ~ as.integer(10),\n    storey_range == \"31 TO 33\" ~ as.integer(11),\n    storey_range == \"34 TO 36\" ~ as.integer(12),\n    storey_range == \"37 TO 39\" ~ as.integer(13),\n    storey_range == \"40 TO 42\" ~ as.integer(14),\n    storey_range == \"43 TO 45\" ~ as.integer(15),\n    storey_range == \"46 TO 48\" ~ as.integer(16),\n    storey_range == \"49 TO 51\" ~ as.integer(17)))\n```\n:::\n\n\n\n\nNow with the basic resale data sort, we would next need to find the geographical location of each of these units, to do this I would first need to get the list of `address` of these units, using the code chunk below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadd_list <- sort(unique(resale_tidy$address))\n```\n:::\n\n\n\n\nThis function below is used to make and API call to [onemap](https://www.onemap.gov.sg) API to extract the coordinate of these units based on its address, this would later be used based on names of shopping malls as well which I will mention.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_coords <- function(add_list){\n  \n  # Create a data frame to store all retrieved coordinates\n  postal_coords <- data.frame()\n    \n  for (i in add_list){\n    #print(i)\n\n    r <- GET('https://www.onemap.gov.sg/api/common/elastic/search?',\n           query=list(searchVal=i,\n                     returnGeom='Y',\n                     getAddrDetails='Y'))\n    data <- fromJSON(rawToChar(r$content))\n    found <- data$found\n    res <- data$results\n    \n    # Create a new data frame for each address\n    new_row <- data.frame()\n    \n    # If single result, append \n    if (found == 1){\n      postal <- res$POSTAL \n      lat <- res$LATITUDE\n      lng <- res$LONGITUDE\n      new_row <- data.frame(address= i, \n                            postal = postal, \n                            latitude = lat, \n                            longitude = lng)\n    }\n    \n    # If multiple results, drop NIL and append top 1\n    else if (found > 1){\n      # Remove those with NIL as postal\n      res_sub <- res[res$POSTAL != \"NIL\", ]\n      \n      # Set as NA first if no Postal\n      if (nrow(res_sub) == 0) {\n          new_row <- data.frame(address= i, \n                                postal = NA, \n                                latitude = NA, \n                                longitude = NA)\n      }\n      \n      else{\n        top1 <- head(res_sub, n = 1)\n        postal <- top1$POSTAL \n        lat <- top1$LATITUDE\n        lng <- top1$LONGITUDE\n        new_row <- data.frame(address= i, \n                              postal = postal, \n                              latitude = lat, \n                              longitude = lng)\n      }\n    }\n\n    else {\n      new_row <- data.frame(address= i, \n                            postal = NA, \n                            latitude = NA, \n                            longitude = NA)\n    }\n    \n    # Add the row\n    postal_coords <- rbind(postal_coords, new_row)\n  }\n  return(postal_coords)\n}\n```\n:::\n\n\n\n\nOnce the function is loaded and the unit address list is created, the below code chunk is run to get all the geo coordinates of these units\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoords <- get_coords(add_list)\n```\n:::\n\n\n\n\nJust in case I will write these coords to a rds file for later usage. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(coords, \"data/rds/coords.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncoords <- read_rds(\"data/rds/coords.rds\")\n```\n:::\n\n\n\n\nThese coordinates is then joined back to the `resale_tidy`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_tidy <- resale_tidy %>% \n  left_join(coords)\n```\n:::\n\n\n\n\nSince the coords would appear as `longitude` and `latitude` which is not `sf` type and would be hard for later analysis, the code chunk below would use the `st_as_sf()` to convert it to a **POINT** geometric instead, then to make sure the `crs` is in correct format of 3414 I will also use `st_transform()`. This code chunk below would create `resale_tidy_final` data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_tidy_final <- resale_tidy %>%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %>%\n  st_transform(crs = 3414)\n```\n:::\n\n\n\n\nJust in case I will write this data to a rds file for later usage. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(resale_tidy_final, \"data/rds/resale_tidy_final.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_tidy_final <- read_rds(\"data/rds/resale_tidy_final.rds\")\n```\n:::\n\n\n\n\nNow, since the study would be focusing on either 3 rooms, 4 rooms or 5 rooms units using 2023 data to predict July-September 2024 data. In this case I would be focusing on 3 rooms analysis and did one more wrangling to filter data to only include 2023 - Sep 2024 and for 3 room units.\n\nThe code chunk below is for this wrangling process\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_final <- resale_tidy_final %>%\n  filter(flat_type == '3 ROOM') %>%\n  filter(month >= \"2023-01\" & month <= \"2024-09\")\n```\n:::\n\n\n\n\n### CBD data\n\nCBD data is using the Master Plan 2014 Subzone Boundary (Web) which I would load and then filter out only the CBD region which includes 'DOWNTOWN CORE', 'MARINA EAST', 'MARINA SOUTH', 'MUSEUM', 'NEWTON', 'ORCHARD', 'OUTRAM', 'RIVER VALLEY', 'ROCHOR', 'SINGAPORE RIVER', 'STRAITS VIEW', `st_transform()` would also be used just in case in the code chunk below creating the `CBD` data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCBD <- st_read(dsn = \"data/geo\", \n                layer = \"MP14_SUBZONE_WEB_PL\") %>%\n  filter(PLN_AREA_N %in% c('DOWNTOWN CORE', 'MARINA EAST', 'MARINA SOUTH',\n                           'MUSEUM', 'NEWTON', 'ORCHARD', 'OUTRAM',\n                           'RIVER VALLEY', 'ROCHOR', 'SINGAPORE RIVER',\n                           'STRAITS VIEW'))%>%\n  st_transform(crs = 3414)\n```\n:::\n\n\n\n\n### Mall list\n\nSince the data is extracted from Wikipedia and only include the mall names, I would need to somehow get the coordinates for these malls. But first the mall list is loaded in creating `mall_list`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmall_list <- read_csv(\"data/non-geo/mall_list.csv\")\n```\n:::\n\n\n\nSimilarly to the `resale` data I wil once again get the `unique` list of `name` instead of address this time with the code chunk below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmall_name <- sort(unique(mall_list$name))\n```\n:::\n\n\n\n\nThen this name list would be feed into the `get_coords()` function creating a new list of coordinations that has the name of the malls and its coords as `longitude` and `latitude` which is not `sf` type and would be hard for later analysis, the code chunk below would use the `st_as_sf()` to convert it to a **POINT** geometric instead and `st_transform()` used to make sure the crs is in correct format. All of this would be done in the code chunk below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmall_list_coords <- get_coords(mall_name) %>%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %>%\n  st_transform(crs = 3414)\n```\n:::\n\n\n\n\nJust in case I will write this data to a rds file for later usage. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(mall_list_coords, \"data/rds/mall_list_coords.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmall <- read_rds(\"data/rds/mall_list_coords.rds\")\n```\n:::\n\n\n\n\n### Primary school list\n\nFirstly since the data Generalinformationofschools.csv file include the list of all schools I would need to extract data to get the necessary information such as name and address. This is done using the code chunk below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nschool_list <- read_csv(\"data/non-geo/Generalinformationofschools.csv\") %>%\n  filter(mainlevel_code == 'PRIMARY') %>%\n  select(1,3)\n```\n:::\n\n\n\nNext similarly to the `resale` data or the `mall` data this address list would be feed into the `get_coords()` function creating a new list of coordinations as `longitude` and `latitude` which is not `sf` type and would be hard for later analysis, the code chunk below would use the `st_as_sf()` to convert it to a **POINT** geometric instead and `st_transform()` used to make sure the crs is in correct format. All of this would be done in the code chunk below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nschool_list_address <- sort(unique(school_list$address))\nschool_list_coords <- get_coords(school_list_address) %>%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %>%\n  st_transform(crs = 3414)\n```\n:::\n\n\n\n\nJust in case I will also write this data to a rds file for later usage. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(school_list_coords, \"data/rds/school_list_coords.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprimary_school <- read_rds(\"data/rds/school_list_coords.rds\")\n```\n:::\n\n\n\n\n### MRT\n\nSince MRT data is already in geographical points I just need to load it in using the code chunk below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMRT <- st_read(dsn = \"data/geo/LTAMRTStationExitGEOJSON.geojson\") %>%\n  st_transform(crs = 3414)\n```\n:::\n\n\n\n\n### Preschool location\n\nPreschool data is already in geographical points I just need to load it in using the code chunk below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreschoolslocation <- st_read(\"data/geo/PreSchoolsLocation.geojson\") %>%\n  st_transform(crs = 3414)\n```\n:::\n\n\n\n\n### Kindergartens\n\nKindergartens data is already in geographical points I just need to load it in using the code chunk below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkindergartens <- st_read(dsn = \"data/geo/Kindergartens.kml\") %>%\n  st_transform(crs = 3414)\n```\n:::\n\n\n\n\n### Supermarkets\n\nSupermarkets data is already in geographical points I just need to load it in using the code chunk below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsupermarkets <- st_read(dsn = \"data/geo/SupermarketsKML.kml\") %>%\n  st_transform(crs = 3414)\n```\n:::\n\n\n\n\n### Eldercare center\n\nElder care center data is already in geographical points I just need to load it in using the code chunk below\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\neldercare <- st_read(dsn = \"data/geo\",\n                     layer = \"ELDERCARE\") %>%\n  st_transform(crs = 3414)\n```\n:::\n\n\n\n\n### Childcare center\n\nChildcare center data is already in geographical points I just need to load it in using the code chunk below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchildcare <- st_read(dsn = \"data/geo\",\n                     layer = \"CHILDCARE\") %>%\n  st_transform(crs = 3414)\n```\n:::\n\n\n\n\n### Bus Stops\n\nBus Stops data is already in geographical points I just need to load it in using the code chunk below. However I do notice during analysis that some of the Bus stops especially '46239', '46609', '47701', '46211', '46219' are located outside of Singapore hence I would remove them from this analysis\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbusstop <- st_read(dsn = \"data/geo\",\n                     layer = \"BusStop\") %>%\n  filter(!BUS_STOP_N %in% c('46239','46609','47701','46211','46219')) %>%\n  st_transform(crs = 3414)\n```\n:::\n\n\n\n\n### CHAS clinics \n\nCHAS clinics data is already in geographical points I just need to load it in using the code chunk below. However I do notice during analysis that one of the clinic 'kml_271' is somehow located outside of Singapore hence I would remove them from this analysis\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCHAS <- st_read(dsn = \"data/geo/CHASClinics.kml\") %>%\n  filter(Name != 'kml_271')%>%\n  st_transform(crs = 3414)\n```\n:::\n\n\n\n\n### Market and foodcentres\n\nMarket and foodcentres data is already in geographical points I just need to load it in using the code chunk below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmarket_foodcentre <- st_read(dsn = \"data/geo/NEAMarketandFoodCentre.geojson\") %>%\n  st_transform(crs = 3414)\n```\n:::\n\n\n\n\n### Parks\n\nParks data is already in geographical points I just need to load it in using the code chunk below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npark <- st_read(dsn = \"data/geo/ParkFacilitiesGEOJSON.geojson\") %>%\n  st_transform(crs = 3414)\n```\n:::\n\n\n\n\n## 3.2 Second phase of data preparation and wrangling\n\nOnce all the data are loaded in I will move on to the next step of calculating the geographical proximity and the number of facilities within a radius of HDB units.\n\nFirst I will create 2 buffer zone data for these unit at 1000 m or 1 km and 350 m separately. The code chunk below will be for this purpose\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbuffer_1km_HDB  <- st_buffer(resale_final,\n                             dist = 1000)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbuffer_350m_HDB  <- st_buffer(resale_final,\n                             dist = 350)\n```\n:::\n\n\n\n\nOnce the buffer zones are created, new columns are created for the `resale_final` and they each represent the number of facilities within a radius of HDB units either 350 m or 1 km. The function to calculate this number would be based on the `lengths(st_intersects(bufferzone, facility))`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_final$within_350m_kindergartens <- lengths(st_intersects(buffer_350m_HDB, kindergartens))\nresale_final$within_350m_childcare <- lengths(st_intersects(buffer_350m_HDB, childcare))\nresale_final$within_350mm_busstop <- lengths(st_intersects(buffer_350m_HDB, busstop))\nresale_final$within_350mm_preschoolslocation <- lengths(st_intersects(buffer_350m_HDB, preschoolslocation))\nresale_final$within_1km_chas <- lengths(st_intersects(buffer_1km_HDB, CHAS))\nresale_final$within_1km_primary_school <- lengths(st_intersects(buffer_1km_HDB, primary_school))\n```\n:::\n\n\n\n\nNext new columns are created for the `resale_final` and they each represent the minimum distance from a unit to another region (CBD) or to another facility. This calculation is based on the `min(st_distance(HDB, location)))/1000` or is in kilometer shortest distance\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_final <- resale_final %>%\n  rowwise() %>%\n  mutate(prox_CBD =  as.numeric(min(st_distance(geometry, CBD)))/1000) %>%\n  mutate(prox_eldercare =  as.numeric(min(st_distance(geometry, eldercare)))/1000) %>%\n  mutate(prox_market_foodcentre =  as.numeric(min(st_distance(geometry, market_foodcentre)))/1000) %>%\n  mutate(prox_MRT =  as.numeric(min(st_distance(geometry, MRT)))/1000) %>%\n  mutate(prox_park =  as.numeric(min(st_distance(geometry, park)))/1000) %>%\n  mutate(prox_mall =  as.numeric(min(st_distance(geometry, mall)))/1000) %>%\n  mutate(prox_supermarkets =  as.numeric(min(st_distance(geometry, supermarkets)))/1000)\n```\n:::\n\n\n\n\nOnce all this caluclation is done I will write this data to a rds file for later usage. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(resale_final, \"data/rds/resale_final.rds\")\n```\n:::\n\n\n\n\n## 3.3 Third phase of data preparation and wrangling\n\nThis will be the final phase to get all the dat needed for the analysis\n\nFirstly, I will be selecting only the columns that is needed for the analysis using the code chunk below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_final <- read_rds(\"data/rds/resale_final.rds\") %>%\n  select(month, resale_price, floor_area_sqm, storey_level, remaining_lease_time,\n         prox_CBD, prox_eldercare, prox_market_foodcentre, prox_MRT,\n         prox_park, prox_mall, prox_supermarkets, within_350m_kindergartens,\n         within_350m_childcare, within_350mm_busstop, \n         within_350mm_preschoolslocation, within_1km_chas, \n         within_1km_primary_school)\n```\n:::\n\n\n\n\nNext I will check for the duplicated point using the sum of multiplicity or `sum(multiplicity())`, `multiplicity()` is part of `spatstat` package to count the number of duplicates for each point in a spatial point pattern\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(multiplicity(resale_final) > 1)\n```\n:::\n\n\n\n\n:::callout-note\n\nThe above code would return a results of 12 duplicated units points, this has been cut off from running since it taking a long time to run. This indicates that there are units that could be in the same building block or very unlikely, sold multiple time during the study period.\n\n:::\n\n\nTo resolve this issue I will be using `st_jitter()` to which techincally moving points within a short distance to address overlapping points issue. In this case I will move them within a 5 meter radius. The code chunk below is used to do this.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_final <- st_jitter(resale_final, amount = 5)\n```\n:::\n\n\n\n\nOnce this is done we could no longer see any duplicate point by rerunning the previous code/\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(multiplicity(resale_final) > 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\n\n\nNow, since the task specifically specify that I would be using  HDB resale transaction records in 2023 to predict HDB resale prices between July-September 2024. I will split them into 2 part call `resale_main` and `resale_check` filtered by the specific period.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_main <- resale_final %>%\n  filter(month >= \"2023-01\" & month <= \"2023-12\")\n\nresale_check <- resale_final %>%\n  filter(month >= \"2024-07\" & month <= \"2024-09\")\n```\n:::\n\n\n\n\nNext, they would be turn into the data that would be used for training and data for testing and prediction specifically call `train_data` and `test_data`. The code chunk below will be doing the above and I will write this data to a rds file for later usage. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\ntrain_data <- resale_main\ncoords_train <- st_coordinates(resale_main)\n\ntrain_data <- write_rds(train_data, \"data/rds/train_data.rds\")\ncoords_train <- write_rds(coords_train, \"data/rds/coords_train.rds\" )\n\ntest_data <- resale_check\ncoords_test <- st_coordinates(resale_check)\n\ntest_data <- write_rds(test_data, \"data/rds/test_data.rds\")\ncoords_test <- write_rds(coords_test, \"data/rds/coords_test.rds\" )\n```\n:::\n\n\n\n\nNext I would want to check how is the data is doing and see if there was any issue with **Collinearity**. To do this I would first create a new data set without its geometry using the code chunk below\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_main_nogeo <- resale_main %>%\n  st_drop_geometry()\n```\n:::\n\n\n\n\nThis data would then be checked for **Collinearity** using the `corrplot()` of `corrplot` package in the code chunk below\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorrplot::corrplot(cor(resale_main_nogeo[, 2:17]), \n                   diag = FALSE, \n                   order = \"AOE\",\n                   tl.pos = \"td\", \n                   tl.cex = 0.5, \n                   method = \"number\", \n                   type = \"upper\")\n```\n\n::: {.cell-output-display}\n![](Project03_files/figure-html/unnamed-chunk-48-1.png){width=900}\n:::\n:::\n\n\n\n\n:::callout-note\n\nSince none of the correlation is higher/lower than +- 0.7, I will be keeping all the variables for this study\n\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_data <- read_rds(\"data/rds/train_data.rds\")\ntest_data <- read_rds(\"data/rds/test_data.rds\")\ncoords_train <- read_rds(\"data/rds/coords_train.rds\" )\ncoords_test <- read_rds(\"data/rds/coords_test.rds\" )\n```\n:::\n\n\n\n\n\n# 4. Model bulding and callibation\n\n## 4.1 Non-spatial multiple linear regression\n\nThe code chunk below will build the multiple linear regression using the `lm()` of `stats` package to  fit linear multivariate models, all the previously mentioned predictors and variables are included to build this model. Then we would use the `ols_regress()` of `olsrr` to perform the Ordinary least squares regression\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nprice_mlr <- lm(resale_price ~ floor_area_sqm + storey_level + \n                  remaining_lease_time + prox_CBD + prox_eldercare + \n                  prox_market_foodcentre + prox_MRT + prox_park + prox_mall +\n                  prox_supermarkets + within_350m_kindergartens +\n                  within_350m_childcare + within_350mm_busstop + \n                  within_350mm_preschoolslocation + within_1km_chas +\n                  within_1km_primary_school,\n                data=train_data)\nolsrr::ols_regress(price_mlr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                              Model Summary                                \n--------------------------------------------------------------------------\nR                           0.875       RMSE                    42719.098 \nR-Squared                   0.766       MSE                1829816217.009 \nAdj. R-Squared              0.766       Coef. Var                  10.386 \nPred R-Squared              0.764       AIC                    153589.830 \nMAE                     31029.976       SBC                    153711.456 \n--------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                      \n-------------------------------------------------------------------------------\n                    Sum of                                                     \n                   Squares          DF       Mean Square       F          Sig. \n-------------------------------------------------------------------------------\nRegression    3.800424e+13          16      2.375265e+12    1298.089    0.0000 \nResidual      1.159738e+13        6338    1829816217.009                       \nTotal         4.960161e+13        6354                                         \n-------------------------------------------------------------------------------\n\n                                                    Parameter Estimates                                                      \n----------------------------------------------------------------------------------------------------------------------------\n                          model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n----------------------------------------------------------------------------------------------------------------------------\n                    (Intercept)    -159037.708      7560.767                 -21.035    0.000    -173859.370    -144216.045 \n                 floor_area_sqm       5268.250        97.413        0.338     54.082    0.000       5077.287       5459.213 \n                   storey_level       9668.810       325.058        0.200     29.745    0.000       9031.587      10306.033 \n           remaining_lease_time        373.707         3.791        0.849     98.581    0.000        366.276        381.139 \n                       prox_CBD      -9842.643       183.872       -0.457    -53.530    0.000     -10203.095      -9482.191 \n                 prox_eldercare       3837.286      1118.404        0.024      3.431    0.001       1644.835       6029.736 \n         prox_market_foodcentre     -15096.642       603.961       -0.235    -24.996    0.000     -16280.609     -13912.674 \n                       prox_MRT     -30707.664      1653.726       -0.126    -18.569    0.000     -33949.527     -27465.801 \n                      prox_park     -17357.348      2233.627       -0.050     -7.771    0.000     -21736.013     -12978.683 \n                      prox_mall     -16171.291      1665.034       -0.066     -9.712    0.000     -19435.321     -12907.260 \n              prox_supermarkets      25146.697      3034.004        0.055      8.288    0.000      19199.023      31094.371 \n      within_350m_kindergartens       5560.911       897.766        0.056      6.194    0.000       3800.986       7320.837 \n          within_350m_childcare        959.410       217.318        0.032      4.415    0.000        533.392       1385.427 \n           within_350mm_busstop        572.749       213.877        0.017      2.678    0.007        153.477        992.020 \nwithin_350mm_preschoolslocation      -2078.563       355.906       -0.059     -5.840    0.000      -2776.259      -1380.866 \n                within_1km_chas       -358.466        88.349       -0.033     -4.057    0.000       -531.660       -185.272 \n      within_1km_primary_school       4499.554       496.240        0.071      9.067    0.000       3526.756       5472.353 \n----------------------------------------------------------------------------------------------------------------------------\n```\n\n\n:::\n:::\n\n\n\n\n:::callout-note\n\nThe model has an Adj. R-Squared of 0.766 which is not bad but also not great and I believe we could do better than this, ANOVA results show that the differences between variables are statistically significant and are unlikely to be due to chance\n\nIts AIC (Akaike Information Criteria) 153589.830 would be kept in mind for later comparison of other models\n\n:::\n\nNext we will calculating the variance inflation factor (VIF) using the `check_collinearity()` of the `performance` package, and then explore its results within the table created by the `kable()` from either `kableExtra` or `knitr` package\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvif <- check_collinearity(price_mlr)\nkable(vif, \n      caption = \"Variance Inflation Factor (VIF) Results\") %>%\n  kable_styling(font_size = 18) \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 18px; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">Variance Inflation Factor (VIF) Results</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Term </th>\n   <th style=\"text-align:right;\"> VIF </th>\n   <th style=\"text-align:right;\"> VIF_CI_low </th>\n   <th style=\"text-align:right;\"> VIF_CI_high </th>\n   <th style=\"text-align:right;\"> SE_factor </th>\n   <th style=\"text-align:right;\"> Tolerance </th>\n   <th style=\"text-align:right;\"> Tolerance_CI_low </th>\n   <th style=\"text-align:right;\"> Tolerance_CI_high </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> floor_area_sqm </td>\n   <td style=\"text-align:right;\"> 1.057888 </td>\n   <td style=\"text-align:right;\"> 1.036092 </td>\n   <td style=\"text-align:right;\"> 1.092846 </td>\n   <td style=\"text-align:right;\"> 1.028537 </td>\n   <td style=\"text-align:right;\"> 0.9452798 </td>\n   <td style=\"text-align:right;\"> 0.9150417 </td>\n   <td style=\"text-align:right;\"> 0.9651653 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> storey_level </td>\n   <td style=\"text-align:right;\"> 1.219417 </td>\n   <td style=\"text-align:right;\"> 1.186839 </td>\n   <td style=\"text-align:right;\"> 1.257676 </td>\n   <td style=\"text-align:right;\"> 1.104272 </td>\n   <td style=\"text-align:right;\"> 0.8200639 </td>\n   <td style=\"text-align:right;\"> 0.7951171 </td>\n   <td style=\"text-align:right;\"> 0.8425746 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> remaining_lease_time </td>\n   <td style=\"text-align:right;\"> 2.012568 </td>\n   <td style=\"text-align:right;\"> 1.941069 </td>\n   <td style=\"text-align:right;\"> 2.089498 </td>\n   <td style=\"text-align:right;\"> 1.418650 </td>\n   <td style=\"text-align:right;\"> 0.4968776 </td>\n   <td style=\"text-align:right;\"> 0.4785837 </td>\n   <td style=\"text-align:right;\"> 0.5151799 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> prox_CBD </td>\n   <td style=\"text-align:right;\"> 1.978201 </td>\n   <td style=\"text-align:right;\"> 1.908356 </td>\n   <td style=\"text-align:right;\"> 2.053416 </td>\n   <td style=\"text-align:right;\"> 1.406485 </td>\n   <td style=\"text-align:right;\"> 0.5055098 </td>\n   <td style=\"text-align:right;\"> 0.4869934 </td>\n   <td style=\"text-align:right;\"> 0.5240111 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> prox_eldercare </td>\n   <td style=\"text-align:right;\"> 1.314164 </td>\n   <td style=\"text-align:right;\"> 1.276684 </td>\n   <td style=\"text-align:right;\"> 1.356721 </td>\n   <td style=\"text-align:right;\"> 1.146370 </td>\n   <td style=\"text-align:right;\"> 0.7609401 </td>\n   <td style=\"text-align:right;\"> 0.7370710 </td>\n   <td style=\"text-align:right;\"> 0.7832795 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> prox_market_foodcentre </td>\n   <td style=\"text-align:right;\"> 2.400750 </td>\n   <td style=\"text-align:right;\"> 2.310604 </td>\n   <td style=\"text-align:right;\"> 2.497097 </td>\n   <td style=\"text-align:right;\"> 1.549435 </td>\n   <td style=\"text-align:right;\"> 0.4165364 </td>\n   <td style=\"text-align:right;\"> 0.4004650 </td>\n   <td style=\"text-align:right;\"> 0.4327872 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> prox_MRT </td>\n   <td style=\"text-align:right;\"> 1.255822 </td>\n   <td style=\"text-align:right;\"> 1.221328 </td>\n   <td style=\"text-align:right;\"> 1.295691 </td>\n   <td style=\"text-align:right;\"> 1.120634 </td>\n   <td style=\"text-align:right;\"> 0.7962914 </td>\n   <td style=\"text-align:right;\"> 0.7717892 </td>\n   <td style=\"text-align:right;\"> 0.8187806 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> prox_park </td>\n   <td style=\"text-align:right;\"> 1.102899 </td>\n   <td style=\"text-align:right;\"> 1.077209 </td>\n   <td style=\"text-align:right;\"> 1.137135 </td>\n   <td style=\"text-align:right;\"> 1.050190 </td>\n   <td style=\"text-align:right;\"> 0.9067016 </td>\n   <td style=\"text-align:right;\"> 0.8794028 </td>\n   <td style=\"text-align:right;\"> 0.9283247 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> prox_mall </td>\n   <td style=\"text-align:right;\"> 1.260166 </td>\n   <td style=\"text-align:right;\"> 1.225447 </td>\n   <td style=\"text-align:right;\"> 1.300231 </td>\n   <td style=\"text-align:right;\"> 1.122571 </td>\n   <td style=\"text-align:right;\"> 0.7935462 </td>\n   <td style=\"text-align:right;\"> 0.7690939 </td>\n   <td style=\"text-align:right;\"> 0.8160285 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> prox_supermarkets </td>\n   <td style=\"text-align:right;\"> 1.198851 </td>\n   <td style=\"text-align:right;\"> 1.167381 </td>\n   <td style=\"text-align:right;\"> 1.236238 </td>\n   <td style=\"text-align:right;\"> 1.094920 </td>\n   <td style=\"text-align:right;\"> 0.8341322 </td>\n   <td style=\"text-align:right;\"> 0.8089060 </td>\n   <td style=\"text-align:right;\"> 0.8566185 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> within_350m_kindergartens </td>\n   <td style=\"text-align:right;\"> 2.210474 </td>\n   <td style=\"text-align:right;\"> 2.129463 </td>\n   <td style=\"text-align:right;\"> 2.297297 </td>\n   <td style=\"text-align:right;\"> 1.486766 </td>\n   <td style=\"text-align:right;\"> 0.4523916 </td>\n   <td style=\"text-align:right;\"> 0.4352942 </td>\n   <td style=\"text-align:right;\"> 0.4696020 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> within_350m_childcare </td>\n   <td style=\"text-align:right;\"> 1.442154 </td>\n   <td style=\"text-align:right;\"> 1.398298 </td>\n   <td style=\"text-align:right;\"> 1.490838 </td>\n   <td style=\"text-align:right;\"> 1.200897 </td>\n   <td style=\"text-align:right;\"> 0.6934074 </td>\n   <td style=\"text-align:right;\"> 0.6707638 </td>\n   <td style=\"text-align:right;\"> 0.7151550 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> within_350mm_busstop </td>\n   <td style=\"text-align:right;\"> 1.106823 </td>\n   <td style=\"text-align:right;\"> 1.080858 </td>\n   <td style=\"text-align:right;\"> 1.141125 </td>\n   <td style=\"text-align:right;\"> 1.052056 </td>\n   <td style=\"text-align:right;\"> 0.9034869 </td>\n   <td style=\"text-align:right;\"> 0.8763283 </td>\n   <td style=\"text-align:right;\"> 0.9251906 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> within_350mm_preschoolslocation </td>\n   <td style=\"text-align:right;\"> 2.740045 </td>\n   <td style=\"text-align:right;\"> 2.633628 </td>\n   <td style=\"text-align:right;\"> 2.853395 </td>\n   <td style=\"text-align:right;\"> 1.655308 </td>\n   <td style=\"text-align:right;\"> 0.3649575 </td>\n   <td style=\"text-align:right;\"> 0.3504598 </td>\n   <td style=\"text-align:right;\"> 0.3797043 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> within_1km_chas </td>\n   <td style=\"text-align:right;\"> 1.783973 </td>\n   <td style=\"text-align:right;\"> 1.723491 </td>\n   <td style=\"text-align:right;\"> 1.849511 </td>\n   <td style=\"text-align:right;\"> 1.335655 </td>\n   <td style=\"text-align:right;\"> 0.5605466 </td>\n   <td style=\"text-align:right;\"> 0.5406835 </td>\n   <td style=\"text-align:right;\"> 0.5802176 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> within_1km_primary_school </td>\n   <td style=\"text-align:right;\"> 1.681112 </td>\n   <td style=\"text-align:right;\"> 1.625605 </td>\n   <td style=\"text-align:right;\"> 1.741544 </td>\n   <td style=\"text-align:right;\"> 1.296577 </td>\n   <td style=\"text-align:right;\"> 0.5948444 </td>\n   <td style=\"text-align:right;\"> 0.5742032 </td>\n   <td style=\"text-align:right;\"> 0.6151557 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n:::callout-note\n\nVIF itself is below 5 and tolerance is within the 0.25 to 4 hence indicating that there is unlikely any issue with multicollinearity with this regression model\n\n:::\n\nThe plot below is to better visualize the VIF \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(vif) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Project03_files/figure-html/unnamed-chunk-52-1.png){width=1200}\n:::\n:::\n\n\n\n\n## 4.2 Geographically Weighted Regression with gwr method\n\nNext I would try out the Geographically Weighted Regression or gwr method using `GWmodel` package, however just running the model and then calibrating them would take a lot of time hence I would be calibrating the model at the same time.\n\nThe first step is to calibrate the model by calculating the adaptive bandwidth based on the training data or `train_data`. To do this `bw.gwr()` would be used in the code chunk below creating the `bw_adaptive`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nbw_adaptive <- bw.gwr(resale_price ~ floor_area_sqm + storey_level + \n                        remaining_lease_time + prox_CBD + prox_eldercare + \n                        prox_market_foodcentre + prox_MRT + prox_park + prox_mall +\n                        prox_supermarkets + within_350m_kindergartens +\n                        within_350m_childcare + within_350mm_busstop + \n                        within_350mm_preschoolslocation + within_1km_chas +\n                        within_1km_primary_school,\n                      data=train_data,\n                      approach=\"CV\",\n                      kernel=\"gaussian\",\n                      adaptive=TRUE,\n                      longlat=FALSE)\n```\n:::\n\n\n\n\nOnce this has finished running I will write this data to a rds file for later usage \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(bw_adaptive, \"data/rds/bw_adaptive.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbw_adaptive <- read_rds(\"data/rds/bw_adaptive.rds\")\nbw_adaptive\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 38\n```\n\n\n:::\n:::\n\n\n\nThe results is that the calibrated adaptive bandwidth for the model should be 38\n\nThe next step is \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\ngwr_adaptive <- gwr.basic(formula = resale_price ~ floor_area_sqm + storey_level + \n                            remaining_lease_time + prox_CBD + prox_eldercare + \n                            prox_market_foodcentre + prox_MRT + prox_park + prox_mall +\n                            within_350m_childcare + within_350mm_busstop + \n                            within_350mm_preschoolslocation + within_1km_chas +\n                            within_1km_primary_school,\n                          data=train_data,\n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE,\n                          longlat = FALSE)\n```\n:::\n\n\n\n\nOnce this has finished running I will write this data to a rds file for later usage \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(gwr_adaptive, \"data/rds/gwr_adaptive.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngwr_adaptive <- read_rds(\"data/rds/gwr_adaptive.rds\")\ngwr_adaptive\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-11-09 21:02:57.55229 \n   Call:\n   gwr.basic(formula = resale_price ~ floor_area_sqm + storey_level + \n    remaining_lease_time + prox_CBD + prox_eldercare + prox_market_foodcentre + \n    prox_MRT + prox_park + prox_mall + within_350m_childcare + \n    within_350mm_busstop + within_350mm_preschoolslocation + \n    within_1km_chas + within_1km_primary_school, data = train_data, \n    bw = bw_adaptive, kernel = \"gaussian\", adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  resale_price\n   Independent variables:  floor_area_sqm storey_level remaining_lease_time prox_CBD prox_eldercare prox_market_foodcentre prox_MRT prox_park prox_mall within_350m_childcare within_350mm_busstop within_350mm_preschoolslocation within_1km_chas within_1km_primary_school\n   Number of data points: 6355\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-345595  -26786   -3503   21956  535104 \n\n   Coefficients:\n                                     Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)                     -1.510e+05  7.585e+03 -19.904  < 2e-16 ***\n   floor_area_sqm                   5.279e+03  9.815e+01  53.785  < 2e-16 ***\n   storey_level                     9.902e+03  3.270e+02  30.278  < 2e-16 ***\n   remaining_lease_time             3.674e+02  3.765e+00  97.587  < 2e-16 ***\n   prox_CBD                        -9.436e+03  1.805e+02 -52.279  < 2e-16 ***\n   prox_eldercare                   4.321e+03  1.127e+03   3.835 0.000127 ***\n   prox_market_foodcentre          -1.617e+04  5.960e+02 -27.126  < 2e-16 ***\n   prox_MRT                        -2.974e+04  1.663e+03 -17.888  < 2e-16 ***\n   prox_park                       -1.602e+04  2.242e+03  -7.145 9.97e-13 ***\n   prox_mall                       -1.416e+04  1.664e+03  -8.507  < 2e-16 ***\n   within_350m_childcare            8.335e+02  2.177e+02   3.830 0.000130 ***\n   within_350mm_busstop             5.856e+02  2.157e+02   2.715 0.006637 ** \n   within_350mm_preschoolslocation -8.841e+02  2.610e+02  -3.387 0.000711 ***\n   within_1km_chas                 -4.614e+02  8.846e+01  -5.216 1.89e-07 ***\n   within_1km_primary_school        4.307e+03  4.971e+02   8.664  < 2e-16 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 43140 on 6340 degrees of freedom\n   Multiple R-squared: 0.7622\n   Adjusted R-squared: 0.7616 \n   F-statistic:  1451 on 14 and 6340 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 1.17974e+13\n   Sigma(hat): 43092.71\n   AIC:  153694.5\n   AICc:  153694.6\n   BIC:  147587.7\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 38 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                                          Min.     1st Qu.      Median\n   Intercept                       -4.0054e+07 -2.9240e+05 -7.0469e+04\n   floor_area_sqm                  -5.9340e+04  2.5181e+03  3.3501e+03\n   storey_level                    -1.5804e+03  5.6834e+03  7.5921e+03\n   remaining_lease_time            -1.9320e+03  1.8958e+02  2.9800e+02\n   prox_CBD                        -1.3404e+06 -2.7368e+04 -5.5153e+03\n   prox_eldercare                  -7.1923e+05 -5.2017e+03  1.2601e+04\n   prox_market_foodcentre          -4.4488e+06 -2.4613e+04  3.9812e+03\n   prox_MRT                        -1.1081e+06 -7.2842e+04 -3.3150e+04\n   prox_park                       -5.8831e+05 -3.0059e+04  2.7048e+02\n   prox_mall                       -1.8786e+06 -4.2443e+04 -6.8576e+03\n   within_350m_childcare           -5.3707e+04 -2.7396e+03 -1.3046e+02\n   within_350mm_busstop            -1.9138e+04 -1.1816e+03  1.9434e+02\n   within_350mm_preschoolslocation -3.4975e+04 -2.7861e+03 -2.1528e+02\n   within_1km_chas                 -1.2560e+04 -1.2234e+03  1.3256e+02\n   within_1km_primary_school       -3.5193e+05 -7.9389e+03 -1.0362e+02\n                                       3rd Qu.       Max.\n   Intercept                        1.8794e+05 6319227.82\n   floor_area_sqm                   4.4999e+03  127881.24\n   storey_level                     9.2998e+03   19478.85\n   remaining_lease_time             4.3956e+02     794.34\n   prox_CBD                         1.8830e+04 5131948.02\n   prox_eldercare                   4.3843e+04  877257.18\n   prox_market_foodcentre           3.7015e+04  625951.00\n   prox_MRT                        -6.2888e+02  901122.86\n   prox_park                        2.7799e+04 1112226.80\n   prox_mall                        2.2010e+04  666309.80\n   within_350m_childcare            2.7012e+03   31247.77\n   within_350mm_busstop             1.6702e+03   13729.73\n   within_350mm_preschoolslocation  1.7522e+03   29700.89\n   within_1km_chas                  1.7448e+03   27523.38\n   within_1km_primary_school        4.9770e+03  456192.00\n   ************************Diagnostic information*************************\n   Number of data points: 6355 \n   Effective number of parameters (2trace(S) - trace(S'S)): 1168.128 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 5186.872 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 146751.4 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 145452.5 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 146518.1 \n   Residual sum of squares: 2.788363e+12 \n   R-square value:  0.9437848 \n   Adjusted R-square value:  0.9311223 \n\n   ***********************************************************************\n   Program stops at: 2024-11-09 21:03:19.81276 \n```\n\n\n:::\n:::\n\n\n\n\n:::callout-note\n\nInterestingly this gwr.basic() also include the results of another linear regression hence we could quickly compare this result of the GWR model with the previously ran linear model. In this case the Adjusted R-square value of the GWR model is 0.9311223 sinificantly better than 0.76 of the Multilinear regression model. In addition to this its AIC is also at 146751.4 lower than 153694.5 in this model ore the previously recorded 153589.830.\n\nOverall this Geographically Weighted Regression model seems to perform significantly better than the Multilinear regression model\n\n:::\n\nNext I'll calculate the calibration bandwidth for the testing data or `test_data`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\ngwr_bw_test_adaptive <- bw.gwr(resale_price ~ floor_area_sqm + storey_level + \n                                 remaining_lease_time + prox_CBD + prox_eldercare + \n                                 prox_market_foodcentre + prox_MRT + prox_park + prox_mall +\n                                 prox_supermarkets + within_350m_kindergartens +\n                                 within_350m_childcare + within_350mm_busstop +\n                                 within_350mm_preschoolslocation + within_1km_chas +\n                                 within_1km_primary_school,\n                               data=test_data,\n                               approach=\"CV\",\n                               kernel=\"gaussian\",\n                               adaptive=TRUE,\n                               longlat=FALSE)\n```\n:::\n\n\n\n\nOnce this has finished running I will write this data to a rds file for later usage \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(gwr_bw_test_adaptive, \"data/rds/gwr_bw_test_adaptive.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngwr_bw_test_adaptive <- read_rds(\"data/rds/gwr_bw_test_adaptive.rds\")\ngwr_bw_test_adaptive\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 287\n```\n\n\n:::\n:::\n\n\n\nThe results is that the calibrated adaptive bandwidth for the test data should be 38\n\nNext I would attempt to predict the data based on the `train_data` and `test_data` to have something for comparison\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\ngwr_pred <- gwr.predict(resale_price ~ floor_area_sqm + storey_level +\n                          remaining_lease_time + prox_CBD + prox_eldercare +\n                          prox_market_foodcentre + prox_MRT + prox_park + prox_mall +\n                          prox_supermarkets + within_350m_kindergartens +\n                          within_350m_childcare + within_350mm_busstop +\n                          within_350mm_preschoolslocation + within_1km_chas +\n                          within_1km_primary_school,\n                        data=train_data,\n                        predictdata = test_data,\n                        bw=287,\n                        kernel = 'gaussian',\n                        adaptive=TRUE,\n                        longlat = FALSE)\n```\n:::\n\n\n\n\n:::callout-note\n\nUnfortunately, I was not able to overcame the \"no regression point is fixed\" error for this `gwr.predict()` function and unable to showcase them here\n\n:::\n\n\n## 4.3 Geographically Weighted Random Forest method of SpatialML package\n\nFirst let drop the geometry column of training data sets\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_data <- train_data %>% \n  st_drop_geometry()\n```\n:::\n\n\n\n\nThen we would run an inital Random Forest model with default setting to check how well the model would turn out using the `ranger()` of `ranger` package. In addition, I will reduce the number of tree down to 53 instead of 500 since 500 trees would take a lot of time to run for later calibration\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nrf <- ranger(resale_price ~ floor_area_sqm + storey_level + \n               remaining_lease_time + prox_CBD + prox_eldercare + \n               prox_market_foodcentre + prox_MRT + prox_park + prox_mall +\n               prox_supermarkets + within_350m_kindergartens +\n               within_350m_childcare + within_350mm_busstop + \n               within_350mm_preschoolslocation + within_1km_chas +\n               within_1km_primary_school,\n             num.trees = 53,\n             mtry = 5,\n             importance = \"impurity\",\n             data=train_data)\n```\n:::\n\n\n\n\nOnce this has finished running I will write this data to a rds file for later usage \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(rf, \"data/rds/rf.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrf <- read_rds(\"data/rds/rf.rds\")\nrf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_level + remaining_lease_time +      prox_CBD + prox_eldercare + prox_market_foodcentre + prox_MRT +      prox_park + prox_mall + prox_supermarkets + within_350m_kindergartens +      within_350m_childcare + within_350mm_busstop + within_350mm_preschoolslocation +      within_1km_chas + within_1km_primary_school, num.trees = 53,      mtry = 5, importance = \"impurity\", data = train_data) \n\nType:                             Regression \nNumber of trees:                  53 \nSample size:                      6355 \nNumber of independent variables:  16 \nMtry:                             5 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       633848167 \nR squared (OOB):                  0.9188036 \n```\n\n\n:::\n:::\n\n\n\n\n:::callout-note\n\nThis model return a OOB prediction error (MSE) of 636284892 and R squared (OOB) of 0.9184915, based on R squared alone this is a pretty good model.\n\n:::\n\nNext I will attempt to calibrate this model using the `bw_adaptive` of 38 calculated previously and using the `grf()` of `SpacialML` package. This would fit a local version of the Random Forest algorithm, accounting for spatial non-stationarity\n\nThe code chunk below show the code for this.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\ngwRF_adaptive <- grf(formula = resale_price ~ floor_area_sqm + storey_level + \n                       remaining_lease_time + prox_CBD + prox_eldercare + \n                       prox_market_foodcentre + prox_MRT + prox_park + prox_mall +\n                       prox_supermarkets + within_350m_kindergartens +\n                       within_350m_childcare + within_350mm_busstop + \n                       within_350mm_preschoolslocation + within_1km_chas +\n                       within_1km_primary_school,\n                     dframe=train_data,\n                     ntree = 53,\n                     bw=38,\n                     kernel=\"adaptive\",\n                     coords=coords_train)\n```\n:::\n\n\n\n\nOnce this has finished running I will write this data to a rds file for later usage \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(gwRF_adaptive, \"data/rds/gwRF_adaptive.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngwRF_adaptive <- read_rds(\"data/rds/gwRF_adaptive.rds\")\n```\n:::\n\n\n\n\n![](1.png)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngwRF_adaptive$LocalModelSummary\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$l.VariableImportance\n                                      Min          Max        Mean         StD\nfloor_area_sqm                          0 1.444374e+12 12036908744 38731166250\nstorey_level                     44363034 2.112563e+11  6706363630 11869802696\nremaining_lease_time            312420137 4.938088e+11 19019149378 43649567043\nprox_CBD                                0 3.672406e+11  6845136742 20900812241\nprox_eldercare                    8062395 1.036893e+12  7365166244 30251391477\nprox_market_foodcentre            1815629 4.008882e+11  5927098746 17506021731\nprox_MRT                          1871799 9.538612e+11  7094318007 27526763708\nprox_park                         3383980 1.442077e+12  6911451236 30460063518\nprox_mall                         5138662 6.983204e+11  6454574985 26122120904\nprox_supermarkets                       0 1.749969e+12  7368199448 34438841202\nwithin_350m_kindergartens               0 1.154855e+11   987896884  5095969294\nwithin_350m_childcare                   0 1.871588e+11  2809696103 10499177446\nwithin_350mm_busstop                    0 3.120124e+11  3792415215 14101062371\nwithin_350mm_preschoolslocation         0 2.646240e+11  2349973922  7794490999\nwithin_1km_chas                         0 2.410287e+11  4166481778 14685127753\nwithin_1km_primary_school               0 3.213113e+11  2408800082 15656650488\n\n$l.MSE.OOB\n[1] 858973085\n\n$l.r.OOB\n[1] 0.8899476\n\n$l.MSE.Pred\n[1] 82225526\n\n$l.r.Pred\n[1] 0.9894652\n```\n\n\n:::\n:::\n\n\n\n\n:::callout-note\n\nThe results show both Global ML and Local model with R-squared (Not OOB) at 97.845 and R-squared predicted (Not OOB) at 98.947 respectively, which is quite good. In addition to this all AIC metrics (Not OOB) is at 120401.135 and and 115853.725. This seems to indicate that the local of calibrated version of the Geographically Weighted Random Forest seems to be a better model compared to the model ran by default.\n\nOverall, the Machine Learning method of Geographically Weighted Random Forest is performing the best compared to the Geographically Weighted Regression or the Non-spatial multiple linear regression\n\nThe overall trade of is time to run a actually calibrate the model could take a while, for my calibrated Geographically Weighted Random Forest it tooks around 4 hours to finish. Geographically Weighted Regression or the Non-spatial multiple linear regression are performing much better in this regards.\n\n:::\n\nNow that the model is inplace, I'll try to actually predict the data for the July to Sep 2024. Since this the best model, it would be best to use this model to predict data itself to show case its accuracy.\n\nFirst step is to drop the geometry column of test data sets `test_data`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_data <- cbind(test_data, coords_test) %>%\n  st_drop_geometry()\n```\n:::\n\n\n\n\nThen the data would be predicted using the `predict.grf()` method of SpatialML package\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\ngwRF_pred <- predict.grf(gwRF_adaptive, \n                         test_data, \n                         x.var.name=\"X\",\n                         y.var.name=\"Y\", \n                         local.w=1,\n                         global.w=0)\n```\n:::\n\n\n\n\nOnce this has finished running I will write this data to a rds file for later usage \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGRF_pred <- write_rds(gwRF_pred, \"data/rds/GRF_pred.rds\")\n```\n:::\n\n\n\n\nNow with the newly created prediction data, they would be mapped to the original `test_data` using `cbind()` of base R code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGRF_pred <- read_rds(\"data/rds/GRF_pred.rds\")\nGRF_pred_df <- as.data.frame(GRF_pred)\ntest_data_p <- cbind(test_data, GRF_pred_df)\n```\n:::\n\n\n\n\nOnce this has finished running I will write this data to a rds file for later usage \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(test_data_p, \"data/rds/test_data_p.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_data_p <- read_rds(\"data/rds/test_data_p.rds\")\n```\n:::\n\n\n\n\nLet's quickly check the root Root Mean Squared Error between the actual resale price and the predicted data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMetrics::rmse(test_data_p$resale_price, \n     test_data_p$GRF_pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 69067.91\n```\n\n\n:::\n:::\n\n\n\n\nI would now use the `ggplot()` of `ggplot2` package to plot out this grapoh showing prediction data compared to actual data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheme_set(theme_light())\nggplot(data = test_data_p,\n       aes(x = GRF_pred/1000,\n           y = resale_price/1000)) +\n  geom_point() +\n  ggtitle(\"Model prediction graph\") +\n  xlab(\"Resale price (predicted) thousands $SGD\") +\n  ylab(\"Resale price (actual) thousands $SGD\") +\n  geom_abline(color = \"blue4\", size = 1)\n```\n\n::: {.cell-output-display}\n![](Project03_files/figure-html/unnamed-chunk-78-1.png){width=900}\n:::\n:::\n\n\n\n\n:::callout-note\n\nThe graph has an diagonal line and the closer the dots are to the line the more accurate the results were. From initial observation it seems that the model has done ok in term of predicting the resale price of HDB units. \n\nHowever it seems there maybe more or less variables that could be added in or removed to calibrate the model further make its prediction event more accurate. There seems to be more points on the left of the line rather than the right, this signify that the predicted price are often lower than the actual resale prices. This does make sense as all our data actually did not include any economics indicators such as inflation, tax rate raise (2024 in Singapore), etc. Including these metrics in to the model building would greatly improve the model.\n\nIn addition, the appearance of outliers, points more on the top left and top rights has also impacted the model itself and its prediction capability. The exclusion of these outliers could potentially be beneficial for the building of a better model as well.\n\n:::\n\n# 5. Conclusion\n\nOn the above exercise I had test out and calibrate 3 different model Non-spatial multiple linear regression, Geographically Weighted Regression and Geographically Weighted Random Forest. Out of 3 of them the Geographically Weighted Random Forest seems to be performing the best and its predict results seem be most accurate.\n\nOutliers seem to be a potential issue that could impact the prediction power and accuracy of model building. In addition more metrics such as economic indicators are likely important and should be considered further.\n\nOverall this has show case the capability of different model building method for geographical data that could be use in the future for common goods to predicts much more than just the data in this study",
    "supporting": [
      "Project03_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}